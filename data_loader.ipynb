{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(root):\n",
    "    # Load train dataset for generating training data.\n",
    "    with gzip.open(root, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        data = data.reshape(-1, 28, 28)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "# return a tuple of arrays ([all directories inside input path], [all files inside input path])\n",
    "def get_content_of_path(pathname, get_dir=True, get_filenames=True):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in walk(pathname):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    result = []\n",
    "    if get_dir is False:\n",
    "        return filenames\n",
    "    if get_filenames is False:\n",
    "        return dirnames\n",
    "    return dirnames, filenames\n",
    "\n",
    "\n",
    "def get_image_lists_from_dataset(datasets_path):\n",
    "    train_bmode_list = []\n",
    "    train_mask_list = []\n",
    "    test_bmode_list = []\n",
    "    test_mask_list = []\n",
    "\n",
    "    if datasets_path != None:\n",
    "        dataset_list = os.listdir(datasets_path)\n",
    "        for dataset in dataset_list:\n",
    "            bmode_list = [] # input\n",
    "            mask_list = [] # output\n",
    "            dataset_folder = datasets_path + dataset + \"/\"\n",
    "            dataset_dirnames = get_content_of_path(dataset_folder, get_filenames=False)\n",
    "\n",
    "            # loop through image files and put them in list corresponding to their filename\n",
    "            for filename in dataset_dirnames:\n",
    "                if filename != \"bmode\" and filename != \"mask\":\n",
    "                    continue\n",
    "                image_folder = dataset_folder + filename + \"/\"\n",
    "                image_paths = get_content_of_path(image_folder, get_dir=False)\n",
    "                image_paths = [image_folder + image_path for image_path in image_paths]\n",
    "                if filename == \"bmode\":\n",
    "                    bmode_list = image_paths\n",
    "                elif filename == \"mask\":\n",
    "                    mask_list = image_paths\n",
    "\n",
    "            # assign bmode and mask list depending on dataset type\n",
    "            if dataset == \"train\":\n",
    "                train_bmode_list = bmode_list\n",
    "                train_mask_list = mask_list\n",
    "            elif dataset == \"test\":\n",
    "                test_bmode_list = bmode_list\n",
    "                test_mask_list = mask_list\n",
    "    return train_bmode_list, train_mask_list, test_bmode_list, test_mask_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = \"/gpfs/fs2/scratch/mdoyley_lab/GPU_VA/DL_dataset/\"\n",
    "train_bmode, train_mask, test_bmode, test_mask = get_image_lists_from_dataset(datasets_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "# convert an array of image directory to an array of tensors\n",
    "def img_to_tensor(img_dir_array):\n",
    "    # tensor converter\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    # resulting tensor array\n",
    "    img_tensor_array = []\n",
    "    \n",
    "    # start loop through img_dir_array\n",
    "    for img_dir in img_dir_array:\n",
    "        img = Image.open(img_dir)\n",
    "        img_tensor_array.append(convert_tensor(img))\n",
    "    return img_tensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bmode_tensor = img_to_tensor(train_bmode)\n",
    "train_mask_tensor = img_to_tensor(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local_scratch/8181020/ipykernel_3367/1256747230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_bmode_tensor1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bmode_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "train_bmode_tensor1 = torch.Tensor(train_bmode_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/local_scratch/8181020/ipykernel_3367/3301930165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bmode_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "shape(train_bmode_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/local_scratch/8181020/ipykernel_3367/2037841237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bmode_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mask_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "data.TensorDataset(torch.Tensor(train_bmode_tensor), torch.Tensor(train_mask_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.9.1)",
   "language": "python",
   "name": "pytorch-1.9.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
